{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The os module has a perfect method to list files in a directory.\n",
    "- Pandas json normalize could work here but is not necessary to convert the JSON data to a dataframe.\n",
    "- You may need a nested for-loop to access each sale!\n",
    "- We've put a lot of time into creating the structure of this repository, and it's a good example for future projects.  In the file functions_variables.py, there is an example function that you can import and use.  If you have any variables, functions or classes that you want to make, they can be put in the functions_variables.py file and imported into a notebook.  Note that only .py files can be imported into a notebook. If you want to import everything from a .py file, you can use the following:\n",
    "```python\n",
    "from functions_variables import *\n",
    "```\n",
    "If you just import functions_variables, then each object from the file will need to be prepended with \"functions_variables\"\\\n",
    "Using this .py file will keep your notebooks very organized and make it easier to reuse code between notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (this is not an exhaustive list of libraries)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from functions_variables import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Testing files and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dir = '../data/AK_Juneau_0.json'\n",
    "os.path.exists(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load one file first to see what type of data you're dealing with and what attributes it has\n",
    "with open(test_dir) as f:\n",
    "    data_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['total', 'count', 'results'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>branding</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>...</th>\n",
       "      <th>location.address.state_code</th>\n",
       "      <th>location.address.line</th>\n",
       "      <th>location.street_view_url</th>\n",
       "      <th>location.county.fips_code</th>\n",
       "      <th>location.county.name</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>source</th>\n",
       "      <th>products</th>\n",
       "      <th>location.address.coordinate</th>\n",
       "      <th>other_listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-19T20:52:50Z</td>\n",
       "      <td>[carport, community_outdoor_space, cul_de_sac,...</td>\n",
       "      <td>9453-Herbert-Pl_Juneau_AK_99801_M90744-30767</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-06-29T21:16:25.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'EXP Realty LLC - Southeast Alaska',...</td>\n",
       "      <td>554950.0</td>\n",
       "      <td>9074430767</td>\n",
       "      <td>[{'tags': [{'label': 'house_view', 'probabilit...</td>\n",
       "      <td>...</td>\n",
       "      <td>AK</td>\n",
       "      <td>9453 Herbert Pl</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       last_update_date                                               tags  \\\n",
       "0  2023-09-19T20:52:50Z  [carport, community_outdoor_space, cul_de_sac,...   \n",
       "\n",
       "                                      permalink status  \\\n",
       "0  9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold   \n",
       "\n",
       "                     list_date open_houses  \\\n",
       "0  2023-06-29T21:16:25.000000Z        None   \n",
       "\n",
       "                                            branding  list_price property_id  \\\n",
       "0  [{'name': 'EXP Realty LLC - Southeast Alaska',...    554950.0  9074430767   \n",
       "\n",
       "                                              photos  ...  \\\n",
       "0  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
       "\n",
       "  location.address.state_code location.address.line  \\\n",
       "0                          AK       9453 Herbert Pl   \n",
       "\n",
       "                            location.street_view_url  \\\n",
       "0  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "\n",
       "   location.county.fips_code  location.county.name primary_photo  source  \\\n",
       "0                       None                Juneau           NaN     NaN   \n",
       "\n",
       "  products  location.address.coordinate other_listings  \n",
       "0      NaN                          NaN            NaN  \n",
       "\n",
       "[1 rows x 64 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.json_normalize(data_json['data']['results'])\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing file .gitkeep: Expecting value: line 1 column 1 (char 0)\n",
      "AK_Juneau_0.json processed. 1/251 files processed.\n",
      "AK_Juneau_1.json processed. 2/251 files processed.\n",
      "AK_Juneau_2.json processed. 3/251 files processed.\n",
      "AK_Juneau_3.json processed. 4/251 files processed.\n",
      "AK_Juneau_4.json processed. 5/251 files processed.\n",
      "AL_Montgomery_0.json processed. 6/251 files processed.\n",
      "AL_Montgomery_1.json processed. 7/251 files processed.\n",
      "AL_Montgomery_2.json processed. 8/251 files processed.\n",
      "AL_Montgomery_3.json processed. 9/251 files processed.\n",
      "AL_Montgomery_4.json processed. 10/251 files processed.\n",
      "AR_LittleRock_0.json processed. 11/251 files processed.\n",
      "AR_LittleRock_1.json processed. 12/251 files processed.\n",
      "AR_LittleRock_2.json processed. 13/251 files processed.\n",
      "AR_LittleRock_3.json processed. 14/251 files processed.\n",
      "AR_LittleRock_4.json processed. 15/251 files processed.\n",
      "AZ_Phoenix_0.json processed. 16/251 files processed.\n",
      "AZ_Phoenix_1.json processed. 17/251 files processed.\n",
      "AZ_Phoenix_2.json processed. 18/251 files processed.\n",
      "AZ_Phoenix_3.json processed. 19/251 files processed.\n",
      "AZ_Phoenix_4.json processed. 20/251 files processed.\n",
      "CA_Sacramento_0.json processed. 21/251 files processed.\n",
      "CA_Sacramento_1.json processed. 22/251 files processed.\n",
      "CA_Sacramento_2.json processed. 23/251 files processed.\n",
      "CA_Sacramento_3.json processed. 24/251 files processed.\n",
      "CA_Sacramento_4.json processed. 25/251 files processed.\n",
      "CO_Denver_0.json processed. 26/251 files processed.\n",
      "CO_Denver_1.json processed. 27/251 files processed.\n",
      "CO_Denver_2.json processed. 28/251 files processed.\n",
      "CO_Denver_3.json processed. 29/251 files processed.\n",
      "CO_Denver_4.json processed. 30/251 files processed.\n",
      "CT_Hartford_0.json processed. 31/251 files processed.\n",
      "CT_Hartford_1.json processed. 32/251 files processed.\n",
      "CT_Hartford_2.json processed. 33/251 files processed.\n",
      "CT_Hartford_3.json processed. 34/251 files processed.\n",
      "CT_Hartford_4.json processed. 35/251 files processed.\n",
      "DE_Dover_0.json processed. 36/251 files processed.\n",
      "DE_Dover_1.json processed. 37/251 files processed.\n",
      "DE_Dover_2.json processed. 38/251 files processed.\n",
      "DE_Dover_3.json processed. 39/251 files processed.\n",
      "DE_Dover_4.json processed. 40/251 files processed.\n",
      "FL_Tallahassee_0.json processed. 41/251 files processed.\n",
      "FL_Tallahassee_1.json processed. 42/251 files processed.\n",
      "FL_Tallahassee_2.json processed. 43/251 files processed.\n",
      "FL_Tallahassee_3.json processed. 44/251 files processed.\n",
      "FL_Tallahassee_4.json processed. 45/251 files processed.\n",
      "GA_Atlanta_0.json processed. 46/251 files processed.\n",
      "GA_Atlanta_1.json processed. 47/251 files processed.\n",
      "GA_Atlanta_2.json processed. 48/251 files processed.\n",
      "GA_Atlanta_3.json processed. 49/251 files processed.\n",
      "GA_Atlanta_4.json processed. 50/251 files processed.\n",
      "HI_Honolulu_0.json processed. 51/251 files processed.\n",
      "HI_Honolulu_1.json processed. 52/251 files processed.\n",
      "HI_Honolulu_2.json processed. 53/251 files processed.\n",
      "HI_Honolulu_3.json processed. 54/251 files processed.\n",
      "HI_Honolulu_4.json processed. 55/251 files processed.\n",
      "IA_DesMoines_0.json processed. 56/251 files processed.\n",
      "IA_DesMoines_1.json processed. 57/251 files processed.\n",
      "IA_DesMoines_2.json processed. 58/251 files processed.\n",
      "IA_DesMoines_3.json processed. 59/251 files processed.\n",
      "IA_DesMoines_4.json processed. 60/251 files processed.\n",
      "ID_Boise_0.json processed. 61/251 files processed.\n",
      "ID_Boise_1.json processed. 62/251 files processed.\n",
      "ID_Boise_2.json processed. 63/251 files processed.\n",
      "ID_Boise_3.json processed. 64/251 files processed.\n",
      "ID_Boise_4.json processed. 65/251 files processed.\n",
      "IL_Springfield_0.json processed. 66/251 files processed.\n",
      "IL_Springfield_1.json processed. 67/251 files processed.\n",
      "IL_Springfield_2.json processed. 68/251 files processed.\n",
      "IL_Springfield_3.json processed. 69/251 files processed.\n",
      "IL_Springfield_4.json processed. 70/251 files processed.\n",
      "IN_Indianapolis_0.json processed. 71/251 files processed.\n",
      "IN_Indianapolis_1.json processed. 72/251 files processed.\n",
      "IN_Indianapolis_2.json processed. 73/251 files processed.\n",
      "IN_Indianapolis_3.json processed. 74/251 files processed.\n",
      "IN_Indianapolis_4.json processed. 75/251 files processed.\n",
      "KS_Topeka_0.json processed. 76/251 files processed.\n",
      "KS_Topeka_1.json processed. 77/251 files processed.\n",
      "KS_Topeka_2.json processed. 78/251 files processed.\n",
      "KS_Topeka_3.json processed. 79/251 files processed.\n",
      "KS_Topeka_4.json processed. 80/251 files processed.\n",
      "KY_Frankfort_0.json processed. 81/251 files processed.\n",
      "KY_Frankfort_1.json processed. 82/251 files processed.\n",
      "KY_Frankfort_2.json processed. 83/251 files processed.\n",
      "KY_Frankfort_3.json processed. 84/251 files processed.\n",
      "KY_Frankfort_4.json processed. 85/251 files processed.\n",
      "LA_BatonRouge_0.json processed. 86/251 files processed.\n",
      "LA_BatonRouge_1.json processed. 87/251 files processed.\n",
      "LA_BatonRouge_2.json processed. 88/251 files processed.\n",
      "LA_BatonRouge_3.json processed. 89/251 files processed.\n",
      "LA_BatonRouge_4.json processed. 90/251 files processed.\n",
      "MA_Boston_0.json processed. 91/251 files processed.\n",
      "MA_Boston_1.json processed. 92/251 files processed.\n",
      "MA_Boston_2.json processed. 93/251 files processed.\n",
      "MA_Boston_3.json processed. 94/251 files processed.\n",
      "MA_Boston_4.json processed. 95/251 files processed.\n",
      "MD_Annapolis_0.json processed. 96/251 files processed.\n",
      "MD_Annapolis_1.json processed. 97/251 files processed.\n",
      "MD_Annapolis_2.json processed. 98/251 files processed.\n",
      "MD_Annapolis_3.json processed. 99/251 files processed.\n",
      "MD_Annapolis_4.json processed. 100/251 files processed.\n",
      "ME_Augusta_0.json processed. 101/251 files processed.\n",
      "ME_Augusta_1.json processed. 102/251 files processed.\n",
      "ME_Augusta_2.json processed. 103/251 files processed.\n",
      "ME_Augusta_3.json processed. 104/251 files processed.\n",
      "ME_Augusta_4.json processed. 105/251 files processed.\n",
      "MI_Lansing_0.json processed. 106/251 files processed.\n",
      "MI_Lansing_1.json processed. 107/251 files processed.\n",
      "MI_Lansing_2.json processed. 108/251 files processed.\n",
      "MI_Lansing_3.json processed. 109/251 files processed.\n",
      "MI_Lansing_4.json processed. 110/251 files processed.\n",
      "MN_St.Paul_0.json processed. 111/251 files processed.\n",
      "MN_St.Paul_1.json processed. 112/251 files processed.\n",
      "MN_St.Paul_2.json processed. 113/251 files processed.\n",
      "MN_St.Paul_3.json processed. 114/251 files processed.\n",
      "MN_St.Paul_4.json processed. 115/251 files processed.\n",
      "MO_JeffersonCity_0.json processed. 116/251 files processed.\n",
      "MO_JeffersonCity_1.json processed. 117/251 files processed.\n",
      "MO_JeffersonCity_2.json processed. 118/251 files processed.\n",
      "MO_JeffersonCity_3.json processed. 119/251 files processed.\n",
      "MO_JeffersonCity_4.json processed. 120/251 files processed.\n",
      "MS_Jackson_0.json processed. 121/251 files processed.\n",
      "MS_Jackson_1.json processed. 122/251 files processed.\n",
      "MS_Jackson_2.json processed. 123/251 files processed.\n",
      "MS_Jackson_3.json processed. 124/251 files processed.\n",
      "MS_Jackson_4.json processed. 125/251 files processed.\n",
      "MT_Helena_0.json processed. 126/251 files processed.\n",
      "MT_Helena_1.json processed. 127/251 files processed.\n",
      "MT_Helena_2.json processed. 128/251 files processed.\n",
      "MT_Helena_3.json processed. 129/251 files processed.\n",
      "MT_Helena_4.json processed. 130/251 files processed.\n",
      "NC_Raleigh_0.json processed. 131/251 files processed.\n",
      "NC_Raleigh_1.json processed. 132/251 files processed.\n",
      "NC_Raleigh_2.json processed. 133/251 files processed.\n",
      "NC_Raleigh_3.json processed. 134/251 files processed.\n",
      "NC_Raleigh_4.json processed. 135/251 files processed.\n",
      "ND_Bismarck_0.json processed. 136/251 files processed.\n",
      "ND_Bismarck_1.json processed. 137/251 files processed.\n",
      "ND_Bismarck_2.json processed. 138/251 files processed.\n",
      "ND_Bismarck_3.json processed. 139/251 files processed.\n",
      "ND_Bismarck_4.json processed. 140/251 files processed.\n",
      "NE_Lincoln_0.json processed. 141/251 files processed.\n",
      "NE_Lincoln_1.json processed. 142/251 files processed.\n",
      "NE_Lincoln_2.json processed. 143/251 files processed.\n",
      "NE_Lincoln_3.json processed. 144/251 files processed.\n",
      "NE_Lincoln_4.json processed. 145/251 files processed.\n",
      "NH_Concord_0.json processed. 146/251 files processed.\n",
      "NH_Concord_1.json processed. 147/251 files processed.\n",
      "NH_Concord_2.json processed. 148/251 files processed.\n",
      "NH_Concord_3.json processed. 149/251 files processed.\n",
      "NH_Concord_4.json processed. 150/251 files processed.\n",
      "NJ_Trenton_0.json processed. 151/251 files processed.\n",
      "NJ_Trenton_1.json processed. 152/251 files processed.\n",
      "NJ_Trenton_2.json processed. 153/251 files processed.\n",
      "NJ_Trenton_3.json processed. 154/251 files processed.\n",
      "NJ_Trenton_4.json processed. 155/251 files processed.\n",
      "NM_SantaFe_0.json processed. 156/251 files processed.\n",
      "NM_SantaFe_1.json processed. 157/251 files processed.\n",
      "NM_SantaFe_2.json processed. 158/251 files processed.\n",
      "NM_SantaFe_3.json processed. 159/251 files processed.\n",
      "NM_SantaFe_4.json processed. 160/251 files processed.\n",
      "NV_CarsonCity_0.json processed. 161/251 files processed.\n",
      "NV_CarsonCity_1.json processed. 162/251 files processed.\n",
      "NV_CarsonCity_2.json processed. 163/251 files processed.\n",
      "NV_CarsonCity_3.json processed. 164/251 files processed.\n",
      "NV_CarsonCity_4.json processed. 165/251 files processed.\n",
      "NY_Albany_0.json processed. 166/251 files processed.\n",
      "NY_Albany_1.json processed. 167/251 files processed.\n",
      "NY_Albany_2.json processed. 168/251 files processed.\n",
      "NY_Albany_3.json processed. 169/251 files processed.\n",
      "NY_Albany_4.json processed. 170/251 files processed.\n",
      "OH_Columbus_0.json processed. 171/251 files processed.\n",
      "OH_Columbus_1.json processed. 172/251 files processed.\n",
      "OH_Columbus_2.json processed. 173/251 files processed.\n",
      "OH_Columbus_3.json processed. 174/251 files processed.\n",
      "OH_Columbus_4.json processed. 175/251 files processed.\n",
      "OK_OklahomaCity_0.json processed. 176/251 files processed.\n",
      "OK_OklahomaCity_1.json processed. 177/251 files processed.\n",
      "OK_OklahomaCity_2.json processed. 178/251 files processed.\n",
      "OK_OklahomaCity_3.json processed. 179/251 files processed.\n",
      "OK_OklahomaCity_4.json processed. 180/251 files processed.\n",
      "OR_Salem_0.json processed. 181/251 files processed.\n",
      "OR_Salem_1.json processed. 182/251 files processed.\n",
      "OR_Salem_2.json processed. 183/251 files processed.\n",
      "OR_Salem_3.json processed. 184/251 files processed.\n",
      "OR_Salem_4.json processed. 185/251 files processed.\n",
      "PA_Harrisburg_0.json processed. 186/251 files processed.\n",
      "PA_Harrisburg_1.json processed. 187/251 files processed.\n",
      "PA_Harrisburg_2.json processed. 188/251 files processed.\n",
      "PA_Harrisburg_3.json processed. 189/251 files processed.\n",
      "PA_Harrisburg_4.json processed. 190/251 files processed.\n",
      "RI_Providence_0.json processed. 191/251 files processed.\n",
      "RI_Providence_1.json processed. 192/251 files processed.\n",
      "RI_Providence_2.json processed. 193/251 files processed.\n",
      "RI_Providence_3.json processed. 194/251 files processed.\n",
      "RI_Providence_4.json processed. 195/251 files processed.\n",
      "SC_Columbia_0.json processed. 196/251 files processed.\n",
      "SC_Columbia_1.json processed. 197/251 files processed.\n",
      "SC_Columbia_2.json processed. 198/251 files processed.\n",
      "SC_Columbia_3.json processed. 199/251 files processed.\n",
      "SC_Columbia_4.json processed. 200/251 files processed.\n",
      "SD_Pierre_0.json processed. 201/251 files processed.\n",
      "SD_Pierre_1.json processed. 202/251 files processed.\n",
      "SD_Pierre_2.json processed. 203/251 files processed.\n",
      "SD_Pierre_3.json processed. 204/251 files processed.\n",
      "SD_Pierre_4.json processed. 205/251 files processed.\n",
      "TN_Nashville_0.json processed. 206/251 files processed.\n",
      "TN_Nashville_1.json processed. 207/251 files processed.\n",
      "TN_Nashville_2.json processed. 208/251 files processed.\n",
      "TN_Nashville_3.json processed. 209/251 files processed.\n",
      "TN_Nashville_4.json processed. 210/251 files processed.\n",
      "TX_Austin_0.json processed. 211/251 files processed.\n",
      "TX_Austin_1.json processed. 212/251 files processed.\n",
      "TX_Austin_2.json processed. 213/251 files processed.\n",
      "TX_Austin_3.json processed. 214/251 files processed.\n",
      "TX_Austin_4.json processed. 215/251 files processed.\n",
      "UT_SaltLakeCity_0.json processed. 216/251 files processed.\n",
      "UT_SaltLakeCity_1.json processed. 217/251 files processed.\n",
      "UT_SaltLakeCity_2.json processed. 218/251 files processed.\n",
      "UT_SaltLakeCity_3.json processed. 219/251 files processed.\n",
      "UT_SaltLakeCity_4.json processed. 220/251 files processed.\n",
      "VA_Richmond_0.json processed. 221/251 files processed.\n",
      "VA_Richmond_1.json processed. 222/251 files processed.\n",
      "VA_Richmond_2.json processed. 223/251 files processed.\n",
      "VA_Richmond_3.json processed. 224/251 files processed.\n",
      "VA_Richmond_4.json processed. 225/251 files processed.\n",
      "VT_Montpelier_0.json processed. 226/251 files processed.\n",
      "VT_Montpelier_1.json processed. 227/251 files processed.\n",
      "VT_Montpelier_2.json processed. 228/251 files processed.\n",
      "VT_Montpelier_3.json processed. 229/251 files processed.\n",
      "VT_Montpelier_4.json processed. 230/251 files processed.\n",
      "WA_Olympia_0.json processed. 231/251 files processed.\n",
      "WA_Olympia_1.json processed. 232/251 files processed.\n",
      "WA_Olympia_2.json processed. 233/251 files processed.\n",
      "WA_Olympia_3.json processed. 234/251 files processed.\n",
      "WA_Olympia_4.json processed. 235/251 files processed.\n",
      "WI_Madison_0.json processed. 236/251 files processed.\n",
      "WI_Madison_1.json processed. 237/251 files processed.\n",
      "WI_Madison_2.json processed. 238/251 files processed.\n",
      "WI_Madison_3.json processed. 239/251 files processed.\n",
      "WI_Madison_4.json processed. 240/251 files processed.\n",
      "WV_Charleston_0.json processed. 241/251 files processed.\n",
      "WV_Charleston_1.json processed. 242/251 files processed.\n",
      "WV_Charleston_2.json processed. 243/251 files processed.\n",
      "WV_Charleston_3.json processed. 244/251 files processed.\n",
      "WV_Charleston_4.json processed. 245/251 files processed.\n",
      "WY_Cheyenne_0.json processed. 246/251 files processed.\n",
      "WY_Cheyenne_1.json processed. 247/251 files processed.\n",
      "WY_Cheyenne_2.json processed. 248/251 files processed.\n",
      "WY_Cheyenne_3.json processed. 249/251 files processed.\n",
      "WY_Cheyenne_4.json processed. 250/251 files processed.\n",
      "\n",
      "Process complete.\n"
     ]
    }
   ],
   "source": [
    "# Getting an overview of the data before combining all the files into one dataframe. This is a custom function in `functions_variables.py` --- It takes in a directory path.\n",
    "overview = json_files_summary('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>rows_count</th>\n",
       "      <th>cols_count</th>\n",
       "      <th>cols_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK_Juneau_0.json</td>\n",
       "      <td>../data\\AK_Juneau_0.json</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK_Juneau_1.json</td>\n",
       "      <td>../data\\AK_Juneau_1.json</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK_Juneau_2.json</td>\n",
       "      <td>../data\\AK_Juneau_2.json</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK_Juneau_3.json</td>\n",
       "      <td>../data\\AK_Juneau_3.json</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK_Juneau_4.json</td>\n",
       "      <td>../data\\AK_Juneau_4.json</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>WY_Cheyenne_0.json</td>\n",
       "      <td>../data\\WY_Cheyenne_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>WY_Cheyenne_1.json</td>\n",
       "      <td>../data\\WY_Cheyenne_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>WY_Cheyenne_2.json</td>\n",
       "      <td>../data\\WY_Cheyenne_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>WY_Cheyenne_3.json</td>\n",
       "      <td>../data\\WY_Cheyenne_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>WY_Cheyenne_4.json</td>\n",
       "      <td>../data\\WY_Cheyenne_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name                   file_path  rows_count  cols_count  \\\n",
       "0      AK_Juneau_0.json    ../data\\AK_Juneau_0.json           8          64   \n",
       "1      AK_Juneau_1.json    ../data\\AK_Juneau_1.json           7          63   \n",
       "2      AK_Juneau_2.json    ../data\\AK_Juneau_2.json           6          63   \n",
       "3      AK_Juneau_3.json    ../data\\AK_Juneau_3.json           5          63   \n",
       "4      AK_Juneau_4.json    ../data\\AK_Juneau_4.json           4          63   \n",
       "..                  ...                         ...         ...         ...   \n",
       "245  WY_Cheyenne_0.json  ../data\\WY_Cheyenne_0.json           1           0   \n",
       "246  WY_Cheyenne_1.json  ../data\\WY_Cheyenne_1.json           1           0   \n",
       "247  WY_Cheyenne_2.json  ../data\\WY_Cheyenne_2.json           1           0   \n",
       "248  WY_Cheyenne_3.json  ../data\\WY_Cheyenne_3.json           1           0   \n",
       "249  WY_Cheyenne_4.json  ../data\\WY_Cheyenne_4.json           1           0   \n",
       "\n",
       "                                             cols_name  \n",
       "0    [last_update_date, tags, permalink, status, li...  \n",
       "1    [primary_photo, last_update_date, source, tags...  \n",
       "2    [primary_photo, last_update_date, source, tags...  \n",
       "3    [primary_photo, last_update_date, source, tags...  \n",
       "4    [primary_photo, last_update_date, source, tags...  \n",
       "..                                                 ...  \n",
       "245                                                 []  \n",
       "246                                                 []  \n",
       "247                                                 []  \n",
       "248                                                 []  \n",
       "249                                                 []  \n",
       "\n",
       "[250 rows x 5 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview\n",
    "# After reviewing the data with Data Wrangler, I found that some files may be missing the 'results' key, or it is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Comparing, Checking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['total', 'count', 'results'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 226 -- just chose one of the files that has an empty 'results' key\n",
    "weird_file_path = overview.iloc[226]['file_path']\n",
    "\n",
    "with open(weird_file_path) as f:\n",
    "  weird_file = json.load(f)\n",
    "\n",
    "weird_file['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 8)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weird_file['data']['results']), len(data_json['data']['results']) # Weird vs Normal File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>rows_count</th>\n",
       "      <th>cols_count</th>\n",
       "      <th>cols_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>HI_Honolulu_3.json</td>\n",
       "      <td>../data\\HI_Honolulu_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>HI_Honolulu_4.json</td>\n",
       "      <td>../data\\HI_Honolulu_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>ME_Augusta_0.json</td>\n",
       "      <td>../data\\ME_Augusta_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ME_Augusta_1.json</td>\n",
       "      <td>../data\\ME_Augusta_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>ME_Augusta_2.json</td>\n",
       "      <td>../data\\ME_Augusta_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>ME_Augusta_3.json</td>\n",
       "      <td>../data\\ME_Augusta_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>ME_Augusta_4.json</td>\n",
       "      <td>../data\\ME_Augusta_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>MS_Jackson_0.json</td>\n",
       "      <td>../data\\MS_Jackson_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>MS_Jackson_1.json</td>\n",
       "      <td>../data\\MS_Jackson_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>MS_Jackson_2.json</td>\n",
       "      <td>../data\\MS_Jackson_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>MS_Jackson_3.json</td>\n",
       "      <td>../data\\MS_Jackson_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>MS_Jackson_4.json</td>\n",
       "      <td>../data\\MS_Jackson_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>ND_Bismarck_2.json</td>\n",
       "      <td>../data\\ND_Bismarck_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>ND_Bismarck_3.json</td>\n",
       "      <td>../data\\ND_Bismarck_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>ND_Bismarck_4.json</td>\n",
       "      <td>../data\\ND_Bismarck_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NH_Concord_3.json</td>\n",
       "      <td>../data\\NH_Concord_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>NH_Concord_4.json</td>\n",
       "      <td>../data\\NH_Concord_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>SD_Pierre_0.json</td>\n",
       "      <td>../data\\SD_Pierre_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>SD_Pierre_1.json</td>\n",
       "      <td>../data\\SD_Pierre_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>SD_Pierre_2.json</td>\n",
       "      <td>../data\\SD_Pierre_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>SD_Pierre_3.json</td>\n",
       "      <td>../data\\SD_Pierre_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>SD_Pierre_4.json</td>\n",
       "      <td>../data\\SD_Pierre_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>VT_Montpelier_0.json</td>\n",
       "      <td>../data\\VT_Montpelier_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>VT_Montpelier_1.json</td>\n",
       "      <td>../data\\VT_Montpelier_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>VT_Montpelier_2.json</td>\n",
       "      <td>../data\\VT_Montpelier_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>VT_Montpelier_3.json</td>\n",
       "      <td>../data\\VT_Montpelier_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>VT_Montpelier_4.json</td>\n",
       "      <td>../data\\VT_Montpelier_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>WY_Cheyenne_0.json</td>\n",
       "      <td>../data\\WY_Cheyenne_0.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>WY_Cheyenne_1.json</td>\n",
       "      <td>../data\\WY_Cheyenne_1.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>WY_Cheyenne_2.json</td>\n",
       "      <td>../data\\WY_Cheyenne_2.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>WY_Cheyenne_3.json</td>\n",
       "      <td>../data\\WY_Cheyenne_3.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>WY_Cheyenne_4.json</td>\n",
       "      <td>../data\\WY_Cheyenne_4.json</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name                     file_path  rows_count  \\\n",
       "53     HI_Honolulu_3.json    ../data\\HI_Honolulu_3.json           1   \n",
       "54     HI_Honolulu_4.json    ../data\\HI_Honolulu_4.json           1   \n",
       "100     ME_Augusta_0.json     ../data\\ME_Augusta_0.json           1   \n",
       "101     ME_Augusta_1.json     ../data\\ME_Augusta_1.json           1   \n",
       "102     ME_Augusta_2.json     ../data\\ME_Augusta_2.json           1   \n",
       "103     ME_Augusta_3.json     ../data\\ME_Augusta_3.json           1   \n",
       "104     ME_Augusta_4.json     ../data\\ME_Augusta_4.json           1   \n",
       "120     MS_Jackson_0.json     ../data\\MS_Jackson_0.json           1   \n",
       "121     MS_Jackson_1.json     ../data\\MS_Jackson_1.json           1   \n",
       "122     MS_Jackson_2.json     ../data\\MS_Jackson_2.json           1   \n",
       "123     MS_Jackson_3.json     ../data\\MS_Jackson_3.json           1   \n",
       "124     MS_Jackson_4.json     ../data\\MS_Jackson_4.json           1   \n",
       "137    ND_Bismarck_2.json    ../data\\ND_Bismarck_2.json           1   \n",
       "138    ND_Bismarck_3.json    ../data\\ND_Bismarck_3.json           1   \n",
       "139    ND_Bismarck_4.json    ../data\\ND_Bismarck_4.json           1   \n",
       "148     NH_Concord_3.json     ../data\\NH_Concord_3.json           1   \n",
       "149     NH_Concord_4.json     ../data\\NH_Concord_4.json           1   \n",
       "200      SD_Pierre_0.json      ../data\\SD_Pierre_0.json           1   \n",
       "201      SD_Pierre_1.json      ../data\\SD_Pierre_1.json           1   \n",
       "202      SD_Pierre_2.json      ../data\\SD_Pierre_2.json           1   \n",
       "203      SD_Pierre_3.json      ../data\\SD_Pierre_3.json           1   \n",
       "204      SD_Pierre_4.json      ../data\\SD_Pierre_4.json           1   \n",
       "225  VT_Montpelier_0.json  ../data\\VT_Montpelier_0.json           1   \n",
       "226  VT_Montpelier_1.json  ../data\\VT_Montpelier_1.json           1   \n",
       "227  VT_Montpelier_2.json  ../data\\VT_Montpelier_2.json           1   \n",
       "228  VT_Montpelier_3.json  ../data\\VT_Montpelier_3.json           1   \n",
       "229  VT_Montpelier_4.json  ../data\\VT_Montpelier_4.json           1   \n",
       "245    WY_Cheyenne_0.json    ../data\\WY_Cheyenne_0.json           1   \n",
       "246    WY_Cheyenne_1.json    ../data\\WY_Cheyenne_1.json           1   \n",
       "247    WY_Cheyenne_2.json    ../data\\WY_Cheyenne_2.json           1   \n",
       "248    WY_Cheyenne_3.json    ../data\\WY_Cheyenne_3.json           1   \n",
       "249    WY_Cheyenne_4.json    ../data\\WY_Cheyenne_4.json           1   \n",
       "\n",
       "     cols_count cols_name  \n",
       "53            0        []  \n",
       "54            0        []  \n",
       "100           0        []  \n",
       "101           0        []  \n",
       "102           0        []  \n",
       "103           0        []  \n",
       "104           0        []  \n",
       "120           0        []  \n",
       "121           0        []  \n",
       "122           0        []  \n",
       "123           0        []  \n",
       "124           0        []  \n",
       "137           0        []  \n",
       "138           0        []  \n",
       "139           0        []  \n",
       "148           0        []  \n",
       "149           0        []  \n",
       "200           0        []  \n",
       "201           0        []  \n",
       "202           0        []  \n",
       "203           0        []  \n",
       "204           0        []  \n",
       "225           0        []  \n",
       "226           0        []  \n",
       "227           0        []  \n",
       "228           0        []  \n",
       "229           0        []  \n",
       "245           0        []  \n",
       "246           0        []  \n",
       "247           0        []  \n",
       "248           0        []  \n",
       "249           0        []  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weird_files = overview[overview['cols_count'] == 0]\n",
    "\n",
    "weird_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\HI_Honolulu_3.json returns empty 'results'\n",
      "../data\\HI_Honolulu_4.json returns empty 'results'\n",
      "../data\\ME_Augusta_0.json returns empty 'results'\n",
      "../data\\ME_Augusta_1.json returns empty 'results'\n",
      "../data\\ME_Augusta_2.json returns empty 'results'\n",
      "../data\\ME_Augusta_3.json returns empty 'results'\n",
      "../data\\ME_Augusta_4.json returns empty 'results'\n",
      "../data\\MS_Jackson_0.json returns empty 'results'\n",
      "../data\\MS_Jackson_1.json returns empty 'results'\n",
      "../data\\MS_Jackson_2.json returns empty 'results'\n",
      "../data\\MS_Jackson_3.json returns empty 'results'\n",
      "../data\\MS_Jackson_4.json returns empty 'results'\n",
      "../data\\ND_Bismarck_2.json returns empty 'results'\n",
      "../data\\ND_Bismarck_3.json returns empty 'results'\n",
      "../data\\ND_Bismarck_4.json returns empty 'results'\n",
      "../data\\NH_Concord_3.json returns empty 'results'\n",
      "../data\\NH_Concord_4.json returns empty 'results'\n",
      "../data\\SD_Pierre_0.json returns empty 'results'\n",
      "../data\\SD_Pierre_1.json returns empty 'results'\n",
      "../data\\SD_Pierre_2.json returns empty 'results'\n",
      "../data\\SD_Pierre_3.json returns empty 'results'\n",
      "../data\\SD_Pierre_4.json returns empty 'results'\n",
      "../data\\VT_Montpelier_0.json returns empty 'results'\n",
      "../data\\VT_Montpelier_1.json returns empty 'results'\n",
      "../data\\VT_Montpelier_2.json returns empty 'results'\n",
      "../data\\VT_Montpelier_3.json returns empty 'results'\n",
      "../data\\VT_Montpelier_4.json returns empty 'results'\n",
      "../data\\WY_Cheyenne_0.json returns empty 'results'\n",
      "../data\\WY_Cheyenne_1.json returns empty 'results'\n",
      "../data\\WY_Cheyenne_2.json returns empty 'results'\n",
      "../data\\WY_Cheyenne_3.json returns empty 'results'\n",
      "../data\\WY_Cheyenne_4.json returns empty 'results'\n"
     ]
    }
   ],
   "source": [
    "# Create a list of files with an empty 'results' key or has other problems\n",
    "weird = []\n",
    "extra_weird = []\n",
    "  \n",
    "for file in weird_files['file_path']:\n",
    "  \n",
    "  with open(file) as f:\n",
    "    weird_file = json.load(f)\n",
    "  \n",
    "  if len(weird_file['data']['results']) == 0:\n",
    "    print(f'{file} returns empty \\'results\\'')\n",
    "    weird.append(file)\n",
    "  \n",
    "  else:\n",
    "    print(f'{file} has another problem...')\n",
    "    extra_weird.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "32 Weird Files...\n",
      "['../data\\\\HI_Honolulu_3.json', '../data\\\\HI_Honolulu_4.json', '../data\\\\ME_Augusta_0.json', '../data\\\\ME_Augusta_1.json', '../data\\\\ME_Augusta_2.json', '../data\\\\ME_Augusta_3.json', '../data\\\\ME_Augusta_4.json', '../data\\\\MS_Jackson_0.json', '../data\\\\MS_Jackson_1.json', '../data\\\\MS_Jackson_2.json', '../data\\\\MS_Jackson_3.json', '../data\\\\MS_Jackson_4.json', '../data\\\\ND_Bismarck_2.json', '../data\\\\ND_Bismarck_3.json', '../data\\\\ND_Bismarck_4.json', '../data\\\\NH_Concord_3.json', '../data\\\\NH_Concord_4.json', '../data\\\\SD_Pierre_0.json', '../data\\\\SD_Pierre_1.json', '../data\\\\SD_Pierre_2.json', '../data\\\\SD_Pierre_3.json', '../data\\\\SD_Pierre_4.json', '../data\\\\VT_Montpelier_0.json', '../data\\\\VT_Montpelier_1.json', '../data\\\\VT_Montpelier_2.json', '../data\\\\VT_Montpelier_3.json', '../data\\\\VT_Montpelier_4.json', '../data\\\\WY_Cheyenne_0.json', '../data\\\\WY_Cheyenne_1.json', '../data\\\\WY_Cheyenne_2.json', '../data\\\\WY_Cheyenne_3.json', '../data\\\\WY_Cheyenne_4.json']\n",
      "\n",
      "0 Extra Weird Files... \n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(f'\\n{len(weird)} Weird Files...\\n{weird}')\n",
    "print(f'\\n{len(extra_weird)} Extra Weird Files... \\n{extra_weird}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe to drop the weird files from the overview dataframe\n",
    "drop = [i for i in weird_files.index]\n",
    "\n",
    "overview.drop(drop, inplace=True) # Originally 250, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 5)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>rows_count</th>\n",
       "      <th>cols_count</th>\n",
       "      <th>cols_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AK_Juneau_0.json</td>\n",
       "      <td>../data\\AK_Juneau_0.json</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK_Juneau_1.json</td>\n",
       "      <td>../data\\AK_Juneau_1.json</td>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AK_Juneau_2.json</td>\n",
       "      <td>../data\\AK_Juneau_2.json</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AK_Juneau_3.json</td>\n",
       "      <td>../data\\AK_Juneau_3.json</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AK_Juneau_4.json</td>\n",
       "      <td>../data\\AK_Juneau_4.json</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>[primary_photo, last_update_date, source, tags...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>WV_Charleston_0.json</td>\n",
       "      <td>../data\\WV_Charleston_0.json</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>WV_Charleston_1.json</td>\n",
       "      <td>../data\\WV_Charleston_1.json</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>WV_Charleston_2.json</td>\n",
       "      <td>../data\\WV_Charleston_2.json</td>\n",
       "      <td>41</td>\n",
       "      <td>61</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>WV_Charleston_3.json</td>\n",
       "      <td>../data\\WV_Charleston_3.json</td>\n",
       "      <td>40</td>\n",
       "      <td>61</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>WV_Charleston_4.json</td>\n",
       "      <td>../data\\WV_Charleston_4.json</td>\n",
       "      <td>39</td>\n",
       "      <td>61</td>\n",
       "      <td>[last_update_date, tags, permalink, status, li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                file_name                     file_path  rows_count  \\\n",
       "0        AK_Juneau_0.json      ../data\\AK_Juneau_0.json           8   \n",
       "1        AK_Juneau_1.json      ../data\\AK_Juneau_1.json           7   \n",
       "2        AK_Juneau_2.json      ../data\\AK_Juneau_2.json           6   \n",
       "3        AK_Juneau_3.json      ../data\\AK_Juneau_3.json           5   \n",
       "4        AK_Juneau_4.json      ../data\\AK_Juneau_4.json           4   \n",
       "..                    ...                           ...         ...   \n",
       "240  WV_Charleston_0.json  ../data\\WV_Charleston_0.json          42   \n",
       "241  WV_Charleston_1.json  ../data\\WV_Charleston_1.json          42   \n",
       "242  WV_Charleston_2.json  ../data\\WV_Charleston_2.json          41   \n",
       "243  WV_Charleston_3.json  ../data\\WV_Charleston_3.json          40   \n",
       "244  WV_Charleston_4.json  ../data\\WV_Charleston_4.json          39   \n",
       "\n",
       "     cols_count                                          cols_name  \n",
       "0            64  [last_update_date, tags, permalink, status, li...  \n",
       "1            63  [primary_photo, last_update_date, source, tags...  \n",
       "2            63  [primary_photo, last_update_date, source, tags...  \n",
       "3            63  [primary_photo, last_update_date, source, tags...  \n",
       "4            63  [primary_photo, last_update_date, source, tags...  \n",
       "..          ...                                                ...  \n",
       "240          61  [last_update_date, tags, permalink, status, li...  \n",
       "241          61  [last_update_date, tags, permalink, status, li...  \n",
       "242          61  [last_update_date, tags, permalink, status, li...  \n",
       "243          61  [last_update_date, tags, permalink, status, li...  \n",
       "244          61  [last_update_date, tags, permalink, status, li...  \n",
       "\n",
       "[218 rows x 5 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview # I will use the file_path column to load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Resuming Data Import Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_update_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>permalink</th>\n",
       "      <th>status</th>\n",
       "      <th>list_date</th>\n",
       "      <th>open_houses</th>\n",
       "      <th>branding</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>photos</th>\n",
       "      <th>...</th>\n",
       "      <th>location.address.state_code</th>\n",
       "      <th>location.address.line</th>\n",
       "      <th>location.street_view_url</th>\n",
       "      <th>location.county.fips_code</th>\n",
       "      <th>location.county.name</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>source</th>\n",
       "      <th>products</th>\n",
       "      <th>location.address.coordinate</th>\n",
       "      <th>other_listings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-19T20:52:50Z</td>\n",
       "      <td>[carport, community_outdoor_space, cul_de_sac,...</td>\n",
       "      <td>9453-Herbert-Pl_Juneau_AK_99801_M90744-30767</td>\n",
       "      <td>sold</td>\n",
       "      <td>2023-06-29T21:16:25.000000Z</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': 'EXP Realty LLC - Southeast Alaska',...</td>\n",
       "      <td>554950.0</td>\n",
       "      <td>9074430767</td>\n",
       "      <td>[{'tags': [{'label': 'house_view', 'probabilit...</td>\n",
       "      <td>...</td>\n",
       "      <td>AK</td>\n",
       "      <td>9453 Herbert Pl</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...</td>\n",
       "      <td>sold</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[{'name': None, 'photo': None, 'type': 'Office'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9424983842</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>AK</td>\n",
       "      <td>8477 Thunder Mountain Rd</td>\n",
       "      <td>https://maps.googleapis.com/maps/api/streetvie...</td>\n",
       "      <td>None</td>\n",
       "      <td>Juneau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       last_update_date                                               tags  \\\n",
       "0  2023-09-19T20:52:50Z  [carport, community_outdoor_space, cul_de_sac,...   \n",
       "1                  None                                               None   \n",
       "\n",
       "                                           permalink status  \\\n",
       "0       9453-Herbert-Pl_Juneau_AK_99801_M90744-30767   sold   \n",
       "1  8477-Thunder-Mountain-Rd_Juneau_AK_99801_M9424...   sold   \n",
       "\n",
       "                     list_date open_houses  \\\n",
       "0  2023-06-29T21:16:25.000000Z        None   \n",
       "1                         None        None   \n",
       "\n",
       "                                            branding  list_price property_id  \\\n",
       "0  [{'name': 'EXP Realty LLC - Southeast Alaska',...    554950.0  9074430767   \n",
       "1  [{'name': None, 'photo': None, 'type': 'Office'}]         NaN  9424983842   \n",
       "\n",
       "                                              photos  ...  \\\n",
       "0  [{'tags': [{'label': 'house_view', 'probabilit...  ...   \n",
       "1                                               None  ...   \n",
       "\n",
       "  location.address.state_code     location.address.line  \\\n",
       "0                          AK           9453 Herbert Pl   \n",
       "1                          AK  8477 Thunder Mountain Rd   \n",
       "\n",
       "                            location.street_view_url  \\\n",
       "0  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "1  https://maps.googleapis.com/maps/api/streetvie...   \n",
       "\n",
       "   location.county.fips_code  location.county.name primary_photo  source  \\\n",
       "0                       None                Juneau           NaN     NaN   \n",
       "1                       None                Juneau           NaN     NaN   \n",
       "\n",
       "  products  location.address.coordinate other_listings  \n",
       "0      NaN                          NaN            NaN  \n",
       "1      NaN                          NaN            NaN  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the custom function `read_json` which takes a file path and returns a DataFrame\n",
    "read_json(test_dir).head(2) # Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data\\AK_Juneau_0.json added to the list. 1/218 processed...\n",
      "../data\\AK_Juneau_1.json added to the list. 2/218 processed...\n",
      "../data\\AK_Juneau_2.json added to the list. 3/218 processed...\n",
      "../data\\AK_Juneau_3.json added to the list. 4/218 processed...\n",
      "../data\\AK_Juneau_4.json added to the list. 5/218 processed...\n",
      "../data\\AL_Montgomery_0.json added to the list. 6/218 processed...\n",
      "../data\\AL_Montgomery_1.json added to the list. 7/218 processed...\n",
      "../data\\AL_Montgomery_2.json added to the list. 8/218 processed...\n",
      "../data\\AL_Montgomery_3.json added to the list. 9/218 processed...\n",
      "../data\\AL_Montgomery_4.json added to the list. 10/218 processed...\n",
      "../data\\AR_LittleRock_0.json added to the list. 11/218 processed...\n",
      "../data\\AR_LittleRock_1.json added to the list. 12/218 processed...\n",
      "../data\\AR_LittleRock_2.json added to the list. 13/218 processed...\n",
      "../data\\AR_LittleRock_3.json added to the list. 14/218 processed...\n",
      "../data\\AR_LittleRock_4.json added to the list. 15/218 processed...\n",
      "../data\\AZ_Phoenix_0.json added to the list. 16/218 processed...\n",
      "../data\\AZ_Phoenix_1.json added to the list. 17/218 processed...\n",
      "../data\\AZ_Phoenix_2.json added to the list. 18/218 processed...\n",
      "../data\\AZ_Phoenix_3.json added to the list. 19/218 processed...\n",
      "../data\\AZ_Phoenix_4.json added to the list. 20/218 processed...\n",
      "../data\\CA_Sacramento_0.json added to the list. 21/218 processed...\n",
      "../data\\CA_Sacramento_1.json added to the list. 22/218 processed...\n",
      "../data\\CA_Sacramento_2.json added to the list. 23/218 processed...\n",
      "../data\\CA_Sacramento_3.json added to the list. 24/218 processed...\n",
      "../data\\CA_Sacramento_4.json added to the list. 25/218 processed...\n",
      "../data\\CO_Denver_0.json added to the list. 26/218 processed...\n",
      "../data\\CO_Denver_1.json added to the list. 27/218 processed...\n",
      "../data\\CO_Denver_2.json added to the list. 28/218 processed...\n",
      "../data\\CO_Denver_3.json added to the list. 29/218 processed...\n",
      "../data\\CO_Denver_4.json added to the list. 30/218 processed...\n",
      "../data\\CT_Hartford_0.json added to the list. 31/218 processed...\n",
      "../data\\CT_Hartford_1.json added to the list. 32/218 processed...\n",
      "../data\\CT_Hartford_2.json added to the list. 33/218 processed...\n",
      "../data\\CT_Hartford_3.json added to the list. 34/218 processed...\n",
      "../data\\CT_Hartford_4.json added to the list. 35/218 processed...\n",
      "../data\\DE_Dover_0.json added to the list. 36/218 processed...\n",
      "../data\\DE_Dover_1.json added to the list. 37/218 processed...\n",
      "../data\\DE_Dover_2.json added to the list. 38/218 processed...\n",
      "../data\\DE_Dover_3.json added to the list. 39/218 processed...\n",
      "../data\\DE_Dover_4.json added to the list. 40/218 processed...\n",
      "../data\\FL_Tallahassee_0.json added to the list. 41/218 processed...\n",
      "../data\\FL_Tallahassee_1.json added to the list. 42/218 processed...\n",
      "../data\\FL_Tallahassee_2.json added to the list. 43/218 processed...\n",
      "../data\\FL_Tallahassee_3.json added to the list. 44/218 processed...\n",
      "../data\\FL_Tallahassee_4.json added to the list. 45/218 processed...\n",
      "../data\\GA_Atlanta_0.json added to the list. 46/218 processed...\n",
      "../data\\GA_Atlanta_1.json added to the list. 47/218 processed...\n",
      "../data\\GA_Atlanta_2.json added to the list. 48/218 processed...\n",
      "../data\\GA_Atlanta_3.json added to the list. 49/218 processed...\n",
      "../data\\GA_Atlanta_4.json added to the list. 50/218 processed...\n",
      "../data\\HI_Honolulu_0.json added to the list. 51/218 processed...\n",
      "../data\\HI_Honolulu_1.json added to the list. 52/218 processed...\n",
      "../data\\HI_Honolulu_2.json added to the list. 53/218 processed...\n",
      "../data\\IA_DesMoines_0.json added to the list. 54/218 processed...\n",
      "../data\\IA_DesMoines_1.json added to the list. 55/218 processed...\n",
      "../data\\IA_DesMoines_2.json added to the list. 56/218 processed...\n",
      "../data\\IA_DesMoines_3.json added to the list. 57/218 processed...\n",
      "../data\\IA_DesMoines_4.json added to the list. 58/218 processed...\n",
      "../data\\ID_Boise_0.json added to the list. 59/218 processed...\n",
      "../data\\ID_Boise_1.json added to the list. 60/218 processed...\n",
      "../data\\ID_Boise_2.json added to the list. 61/218 processed...\n",
      "../data\\ID_Boise_3.json added to the list. 62/218 processed...\n",
      "../data\\ID_Boise_4.json added to the list. 63/218 processed...\n",
      "../data\\IL_Springfield_0.json added to the list. 64/218 processed...\n",
      "../data\\IL_Springfield_1.json added to the list. 65/218 processed...\n",
      "../data\\IL_Springfield_2.json added to the list. 66/218 processed...\n",
      "../data\\IL_Springfield_3.json added to the list. 67/218 processed...\n",
      "../data\\IL_Springfield_4.json added to the list. 68/218 processed...\n",
      "../data\\IN_Indianapolis_0.json added to the list. 69/218 processed...\n",
      "../data\\IN_Indianapolis_1.json added to the list. 70/218 processed...\n",
      "../data\\IN_Indianapolis_2.json added to the list. 71/218 processed...\n",
      "../data\\IN_Indianapolis_3.json added to the list. 72/218 processed...\n",
      "../data\\IN_Indianapolis_4.json added to the list. 73/218 processed...\n",
      "../data\\KS_Topeka_0.json added to the list. 74/218 processed...\n",
      "../data\\KS_Topeka_1.json added to the list. 75/218 processed...\n",
      "../data\\KS_Topeka_2.json added to the list. 76/218 processed...\n",
      "../data\\KS_Topeka_3.json added to the list. 77/218 processed...\n",
      "../data\\KS_Topeka_4.json added to the list. 78/218 processed...\n",
      "../data\\KY_Frankfort_0.json added to the list. 79/218 processed...\n",
      "../data\\KY_Frankfort_1.json added to the list. 80/218 processed...\n",
      "../data\\KY_Frankfort_2.json added to the list. 81/218 processed...\n",
      "../data\\KY_Frankfort_3.json added to the list. 82/218 processed...\n",
      "../data\\KY_Frankfort_4.json added to the list. 83/218 processed...\n",
      "../data\\LA_BatonRouge_0.json added to the list. 84/218 processed...\n",
      "../data\\LA_BatonRouge_1.json added to the list. 85/218 processed...\n",
      "../data\\LA_BatonRouge_2.json added to the list. 86/218 processed...\n",
      "../data\\LA_BatonRouge_3.json added to the list. 87/218 processed...\n",
      "../data\\LA_BatonRouge_4.json added to the list. 88/218 processed...\n",
      "../data\\MA_Boston_0.json added to the list. 89/218 processed...\n",
      "../data\\MA_Boston_1.json added to the list. 90/218 processed...\n",
      "../data\\MA_Boston_2.json added to the list. 91/218 processed...\n",
      "../data\\MA_Boston_3.json added to the list. 92/218 processed...\n",
      "../data\\MA_Boston_4.json added to the list. 93/218 processed...\n",
      "../data\\MD_Annapolis_0.json added to the list. 94/218 processed...\n",
      "../data\\MD_Annapolis_1.json added to the list. 95/218 processed...\n",
      "../data\\MD_Annapolis_2.json added to the list. 96/218 processed...\n",
      "../data\\MD_Annapolis_3.json added to the list. 97/218 processed...\n",
      "../data\\MD_Annapolis_4.json added to the list. 98/218 processed...\n",
      "../data\\MI_Lansing_0.json added to the list. 99/218 processed...\n",
      "../data\\MI_Lansing_1.json added to the list. 100/218 processed...\n",
      "../data\\MI_Lansing_2.json added to the list. 101/218 processed...\n",
      "../data\\MI_Lansing_3.json added to the list. 102/218 processed...\n",
      "../data\\MI_Lansing_4.json added to the list. 103/218 processed...\n",
      "../data\\MN_St.Paul_0.json added to the list. 104/218 processed...\n",
      "../data\\MN_St.Paul_1.json added to the list. 105/218 processed...\n",
      "../data\\MN_St.Paul_2.json added to the list. 106/218 processed...\n",
      "../data\\MN_St.Paul_3.json added to the list. 107/218 processed...\n",
      "../data\\MN_St.Paul_4.json added to the list. 108/218 processed...\n",
      "../data\\MO_JeffersonCity_0.json added to the list. 109/218 processed...\n",
      "../data\\MO_JeffersonCity_1.json added to the list. 110/218 processed...\n",
      "../data\\MO_JeffersonCity_2.json added to the list. 111/218 processed...\n",
      "../data\\MO_JeffersonCity_3.json added to the list. 112/218 processed...\n",
      "../data\\MO_JeffersonCity_4.json added to the list. 113/218 processed...\n",
      "../data\\MT_Helena_0.json added to the list. 114/218 processed...\n",
      "../data\\MT_Helena_1.json added to the list. 115/218 processed...\n",
      "../data\\MT_Helena_2.json added to the list. 116/218 processed...\n",
      "../data\\MT_Helena_3.json added to the list. 117/218 processed...\n",
      "../data\\MT_Helena_4.json added to the list. 118/218 processed...\n",
      "../data\\NC_Raleigh_0.json added to the list. 119/218 processed...\n",
      "../data\\NC_Raleigh_1.json added to the list. 120/218 processed...\n",
      "../data\\NC_Raleigh_2.json added to the list. 121/218 processed...\n",
      "../data\\NC_Raleigh_3.json added to the list. 122/218 processed...\n",
      "../data\\NC_Raleigh_4.json added to the list. 123/218 processed...\n",
      "../data\\ND_Bismarck_0.json added to the list. 124/218 processed...\n",
      "../data\\ND_Bismarck_1.json added to the list. 125/218 processed...\n",
      "../data\\NE_Lincoln_0.json added to the list. 126/218 processed...\n",
      "../data\\NE_Lincoln_1.json added to the list. 127/218 processed...\n",
      "../data\\NE_Lincoln_2.json added to the list. 128/218 processed...\n",
      "../data\\NE_Lincoln_3.json added to the list. 129/218 processed...\n",
      "../data\\NE_Lincoln_4.json added to the list. 130/218 processed...\n",
      "../data\\NH_Concord_0.json added to the list. 131/218 processed...\n",
      "../data\\NH_Concord_1.json added to the list. 132/218 processed...\n",
      "../data\\NH_Concord_2.json added to the list. 133/218 processed...\n",
      "../data\\NJ_Trenton_0.json added to the list. 134/218 processed...\n",
      "../data\\NJ_Trenton_1.json added to the list. 135/218 processed...\n",
      "../data\\NJ_Trenton_2.json added to the list. 136/218 processed...\n",
      "../data\\NJ_Trenton_3.json added to the list. 137/218 processed...\n",
      "../data\\NJ_Trenton_4.json added to the list. 138/218 processed...\n",
      "../data\\NM_SantaFe_0.json added to the list. 139/218 processed...\n",
      "../data\\NM_SantaFe_1.json added to the list. 140/218 processed...\n",
      "../data\\NM_SantaFe_2.json added to the list. 141/218 processed...\n",
      "../data\\NM_SantaFe_3.json added to the list. 142/218 processed...\n",
      "../data\\NM_SantaFe_4.json added to the list. 143/218 processed...\n",
      "../data\\NV_CarsonCity_0.json added to the list. 144/218 processed...\n",
      "../data\\NV_CarsonCity_1.json added to the list. 145/218 processed...\n",
      "../data\\NV_CarsonCity_2.json added to the list. 146/218 processed...\n",
      "../data\\NV_CarsonCity_3.json added to the list. 147/218 processed...\n",
      "../data\\NV_CarsonCity_4.json added to the list. 148/218 processed...\n",
      "../data\\NY_Albany_0.json added to the list. 149/218 processed...\n",
      "../data\\NY_Albany_1.json added to the list. 150/218 processed...\n",
      "../data\\NY_Albany_2.json added to the list. 151/218 processed...\n",
      "../data\\NY_Albany_3.json added to the list. 152/218 processed...\n",
      "../data\\NY_Albany_4.json added to the list. 153/218 processed...\n",
      "../data\\OH_Columbus_0.json added to the list. 154/218 processed...\n",
      "../data\\OH_Columbus_1.json added to the list. 155/218 processed...\n",
      "../data\\OH_Columbus_2.json added to the list. 156/218 processed...\n",
      "../data\\OH_Columbus_3.json added to the list. 157/218 processed...\n",
      "../data\\OH_Columbus_4.json added to the list. 158/218 processed...\n",
      "../data\\OK_OklahomaCity_0.json added to the list. 159/218 processed...\n",
      "../data\\OK_OklahomaCity_1.json added to the list. 160/218 processed...\n",
      "../data\\OK_OklahomaCity_2.json added to the list. 161/218 processed...\n",
      "../data\\OK_OklahomaCity_3.json added to the list. 162/218 processed...\n",
      "../data\\OK_OklahomaCity_4.json added to the list. 163/218 processed...\n",
      "../data\\OR_Salem_0.json added to the list. 164/218 processed...\n",
      "../data\\OR_Salem_1.json added to the list. 165/218 processed...\n",
      "../data\\OR_Salem_2.json added to the list. 166/218 processed...\n",
      "../data\\OR_Salem_3.json added to the list. 167/218 processed...\n",
      "../data\\OR_Salem_4.json added to the list. 168/218 processed...\n",
      "../data\\PA_Harrisburg_0.json added to the list. 169/218 processed...\n",
      "../data\\PA_Harrisburg_1.json added to the list. 170/218 processed...\n",
      "../data\\PA_Harrisburg_2.json added to the list. 171/218 processed...\n",
      "../data\\PA_Harrisburg_3.json added to the list. 172/218 processed...\n",
      "../data\\PA_Harrisburg_4.json added to the list. 173/218 processed...\n",
      "../data\\RI_Providence_0.json added to the list. 174/218 processed...\n",
      "../data\\RI_Providence_1.json added to the list. 175/218 processed...\n",
      "../data\\RI_Providence_2.json added to the list. 176/218 processed...\n",
      "../data\\RI_Providence_3.json added to the list. 177/218 processed...\n",
      "../data\\RI_Providence_4.json added to the list. 178/218 processed...\n",
      "../data\\SC_Columbia_0.json added to the list. 179/218 processed...\n",
      "../data\\SC_Columbia_1.json added to the list. 180/218 processed...\n",
      "../data\\SC_Columbia_2.json added to the list. 181/218 processed...\n",
      "../data\\SC_Columbia_3.json added to the list. 182/218 processed...\n",
      "../data\\SC_Columbia_4.json added to the list. 183/218 processed...\n",
      "../data\\TN_Nashville_0.json added to the list. 184/218 processed...\n",
      "../data\\TN_Nashville_1.json added to the list. 185/218 processed...\n",
      "../data\\TN_Nashville_2.json added to the list. 186/218 processed...\n",
      "../data\\TN_Nashville_3.json added to the list. 187/218 processed...\n",
      "../data\\TN_Nashville_4.json added to the list. 188/218 processed...\n",
      "../data\\TX_Austin_0.json added to the list. 189/218 processed...\n",
      "../data\\TX_Austin_1.json added to the list. 190/218 processed...\n",
      "../data\\TX_Austin_2.json added to the list. 191/218 processed...\n",
      "../data\\TX_Austin_3.json added to the list. 192/218 processed...\n",
      "../data\\TX_Austin_4.json added to the list. 193/218 processed...\n",
      "../data\\UT_SaltLakeCity_0.json added to the list. 194/218 processed...\n",
      "../data\\UT_SaltLakeCity_1.json added to the list. 195/218 processed...\n",
      "../data\\UT_SaltLakeCity_2.json added to the list. 196/218 processed...\n",
      "../data\\UT_SaltLakeCity_3.json added to the list. 197/218 processed...\n",
      "../data\\UT_SaltLakeCity_4.json added to the list. 198/218 processed...\n",
      "../data\\VA_Richmond_0.json added to the list. 199/218 processed...\n",
      "../data\\VA_Richmond_1.json added to the list. 200/218 processed...\n",
      "../data\\VA_Richmond_2.json added to the list. 201/218 processed...\n",
      "../data\\VA_Richmond_3.json added to the list. 202/218 processed...\n",
      "../data\\VA_Richmond_4.json added to the list. 203/218 processed...\n",
      "../data\\WA_Olympia_0.json added to the list. 204/218 processed...\n",
      "../data\\WA_Olympia_1.json added to the list. 205/218 processed...\n",
      "../data\\WA_Olympia_2.json added to the list. 206/218 processed...\n",
      "../data\\WA_Olympia_3.json added to the list. 207/218 processed...\n",
      "../data\\WA_Olympia_4.json added to the list. 208/218 processed...\n",
      "../data\\WI_Madison_0.json added to the list. 209/218 processed...\n",
      "../data\\WI_Madison_1.json added to the list. 210/218 processed...\n",
      "../data\\WI_Madison_2.json added to the list. 211/218 processed...\n",
      "../data\\WI_Madison_3.json added to the list. 212/218 processed...\n",
      "../data\\WI_Madison_4.json added to the list. 213/218 processed...\n",
      "../data\\WV_Charleston_0.json added to the list. 214/218 processed...\n",
      "../data\\WV_Charleston_1.json added to the list. 215/218 processed...\n",
      "../data\\WV_Charleston_2.json added to the list. 216/218 processed...\n",
      "../data\\WV_Charleston_3.json added to the list. 217/218 processed...\n",
      "../data\\WV_Charleston_4.json added to the list. 218/218 processed...\n",
      "\n",
      "218 files loaded into the list of DataFrames.\n"
     ]
    }
   ],
   "source": [
    "# loop over all files and put them into a dataframe\n",
    "combine_all = []\n",
    "\n",
    "for path in overview['file_path']:\n",
    "  df = read_json(path)\n",
    "  combine_all.append(df)\n",
    "  print(f'{path} added to the list. {len(combine_all)}/{overview.shape[0]} processed...')\n",
    "\n",
    "print(f'\\n{len(combine_all)} files loaded into the list of DataFrames.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kadm2\\AppData\\Local\\Temp\\ipykernel_10816\\3315332010.py:1: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  housing_dataset = pd.concat(combine_all, ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8159, 67)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_dataset = pd.concat(combine_all, ignore_index=True)\n",
    "\n",
    "housing_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Saving outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '../outputs'\n",
    "\n",
    "# --- !!! Uncomment only when saving. Run once and put the # back. !!! --- #\n",
    "# housing_dataset.to_csv(os.path.join(output_path, 'housing_dataset.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8159, 67)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df = pd.read_csv(os.path.join(output_path, 'housing_dataset.csv'))\n",
    "\n",
    "housing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, ensure that you have all sales in a dataframe.\n",
    "- Take a quick look at your data (i.e. `.info()`, `.describe()`) - what do you see?\n",
    "- Is each cell one value, or do some cells have lists?\n",
    "- What are the data types of each column?\n",
    "- Some sales may not actually include the sale price (target).  These rows should be dropped.\n",
    "- There are a lot of NA/None values.  Should these be dropped or replaced with something?\n",
    "    - You can drop rows or use various methods to fills NA's - use your best judgement for each column \n",
    "    - i.e. for some columns (like Garage), NA probably just means no Garage, so 0\n",
    "- Drop columns that aren't needed\n",
    "    - Don't keep the list price because it will be too close to the sale price. Assume we want to predict the price of houses not yet listed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Quick look at the data and the values in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = housing_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8159 entries, 0 to 8158\n",
      "Data columns (total 67 columns):\n",
      " #   Column                                 Non-Null Count  Dtype  \n",
      "---  ------                                 --------------  -----  \n",
      " 0   last_update_date                       8125 non-null   object \n",
      " 1   tags                                   7638 non-null   object \n",
      " 2   permalink                              8159 non-null   object \n",
      " 3   status                                 8159 non-null   object \n",
      " 4   list_date                              7752 non-null   object \n",
      " 5   open_houses                            0 non-null      float64\n",
      " 6   branding                               8159 non-null   object \n",
      " 7   list_price                             7721 non-null   float64\n",
      " 8   property_id                            8159 non-null   int64  \n",
      " 9   photos                                 7403 non-null   object \n",
      " 10  community                              0 non-null      float64\n",
      " 11  virtual_tours                          1351 non-null   object \n",
      " 12  listing_id                             7752 non-null   float64\n",
      " 13  price_reduced_amount                   2484 non-null   float64\n",
      " 14  matterport                             8159 non-null   bool   \n",
      " 15  primary_photo.href                     7403 non-null   object \n",
      " 16  source.plan_id                         5 non-null      float64\n",
      " 17  source.agents                          7752 non-null   object \n",
      " 18  source.spec_id                         5 non-null      object \n",
      " 19  source.type                            7752 non-null   object \n",
      " 20  description.year_built                 7316 non-null   float64\n",
      " 21  description.baths_3qtr                 566 non-null    float64\n",
      " 22  description.sold_date                  8159 non-null   object \n",
      " 23  description.sold_price                 6716 non-null   float64\n",
      " 24  description.baths_full                 7311 non-null   float64\n",
      " 25  description.name                       0 non-null      float64\n",
      " 26  description.baths_half                 2281 non-null   float64\n",
      " 27  description.lot_sqft                   6991 non-null   float64\n",
      " 28  description.sqft                       7323 non-null   float64\n",
      " 29  description.baths                      7980 non-null   float64\n",
      " 30  description.sub_type                   1427 non-null   object \n",
      " 31  description.baths_1qtr                 0 non-null      float64\n",
      " 32  description.garage                     4448 non-null   float64\n",
      " 33  description.stories                    6260 non-null   float64\n",
      " 34  description.beds                       7504 non-null   float64\n",
      " 35  description.type                       8125 non-null   object \n",
      " 36  lead_attributes.show_contact_an_agent  8159 non-null   bool   \n",
      " 37  flags.is_new_construction              0 non-null      float64\n",
      " 38  flags.is_for_rent                      0 non-null      float64\n",
      " 39  flags.is_subdivision                   0 non-null      float64\n",
      " 40  flags.is_contingent                    0 non-null      float64\n",
      " 41  flags.is_price_reduced                 2484 non-null   object \n",
      " 42  flags.is_pending                       0 non-null      float64\n",
      " 43  flags.is_foreclosure                   42 non-null     object \n",
      " 44  flags.is_plan                          0 non-null      float64\n",
      " 45  flags.is_coming_soon                   0 non-null      float64\n",
      " 46  flags.is_new_listing                   7752 non-null   object \n",
      " 47  products.brand_name                    7673 non-null   object \n",
      " 48  other_listings.rdc                     7856 non-null   object \n",
      " 49  location.address.postal_code           8159 non-null   int64  \n",
      " 50  location.address.state                 8159 non-null   object \n",
      " 51  location.address.coordinate.lon        7909 non-null   float64\n",
      " 52  location.address.coordinate.lat        7909 non-null   float64\n",
      " 53  location.address.city                  8154 non-null   object \n",
      " 54  location.address.state_code            8159 non-null   object \n",
      " 55  location.address.line                  8144 non-null   object \n",
      " 56  location.street_view_url               8159 non-null   object \n",
      " 57  location.county.fips_code              7588 non-null   float64\n",
      " 58  location.county.name                   8149 non-null   object \n",
      " 59  primary_photo                          0 non-null      float64\n",
      " 60  source                                 0 non-null      float64\n",
      " 61  products                               0 non-null      float64\n",
      " 62  location.address.coordinate            0 non-null      float64\n",
      " 63  other_listings                         0 non-null      float64\n",
      " 64  community.advertisers                  5 non-null      object \n",
      " 65  community.description.name             5 non-null      object \n",
      " 66  location.county                        0 non-null      float64\n",
      "dtypes: bool(2), float64(35), int64(2), object(28)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_houses</th>\n",
       "      <th>list_price</th>\n",
       "      <th>property_id</th>\n",
       "      <th>community</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>price_reduced_amount</th>\n",
       "      <th>source.plan_id</th>\n",
       "      <th>description.year_built</th>\n",
       "      <th>description.baths_3qtr</th>\n",
       "      <th>description.sold_price</th>\n",
       "      <th>...</th>\n",
       "      <th>location.address.postal_code</th>\n",
       "      <th>location.address.coordinate.lon</th>\n",
       "      <th>location.address.coordinate.lat</th>\n",
       "      <th>location.county.fips_code</th>\n",
       "      <th>primary_photo</th>\n",
       "      <th>source</th>\n",
       "      <th>products</th>\n",
       "      <th>location.address.coordinate</th>\n",
       "      <th>other_listings</th>\n",
       "      <th>location.county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.721000e+03</td>\n",
       "      <td>8.159000e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.752000e+03</td>\n",
       "      <td>2.484000e+03</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>7316.000000</td>\n",
       "      <td>566.000000</td>\n",
       "      <td>6.716000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>8159.000000</td>\n",
       "      <td>7909.000000</td>\n",
       "      <td>7909.000000</td>\n",
       "      <td>7588.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.341582e+05</td>\n",
       "      <td>5.755508e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.957819e+09</td>\n",
       "      <td>2.442704e+04</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>1968.916074</td>\n",
       "      <td>1.247350</td>\n",
       "      <td>4.126050e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>50946.997181</td>\n",
       "      <td>-92.206522</td>\n",
       "      <td>39.009689</td>\n",
       "      <td>28000.253295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.514925e+05</td>\n",
       "      <td>2.687366e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.541620e+07</td>\n",
       "      <td>7.162396e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>35.096914</td>\n",
       "      <td>0.463482</td>\n",
       "      <td>6.994308e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>29257.110670</td>\n",
       "      <td>15.888886</td>\n",
       "      <td>4.374553</td>\n",
       "      <td>15586.751739</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.003443e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.052327e+08</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>1828.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.080000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>2111.000000</td>\n",
       "      <td>-157.810583</td>\n",
       "      <td>21.277707</td>\n",
       "      <td>1101.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.090000e+05</td>\n",
       "      <td>3.307743e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.959499e+09</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.910000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>25314.000000</td>\n",
       "      <td>-104.971611</td>\n",
       "      <td>35.688084</td>\n",
       "      <td>16001.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.250000e+05</td>\n",
       "      <td>6.000993e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.960836e+09</td>\n",
       "      <td>1.010000e+04</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.140000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>50310.000000</td>\n",
       "      <td>-89.333131</td>\n",
       "      <td>39.698210</td>\n",
       "      <td>27123.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.999000e+05</td>\n",
       "      <td>8.169927e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.961805e+09</td>\n",
       "      <td>2.000000e+04</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.700000e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>78739.000000</td>\n",
       "      <td>-78.617690</td>\n",
       "      <td>41.832266</td>\n",
       "      <td>41047.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.250000e+07</td>\n",
       "      <td>9.993679e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.963230e+09</td>\n",
       "      <td>2.015999e+06</td>\n",
       "      <td>4.170007e+11</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.706500e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>99801.000000</td>\n",
       "      <td>-71.006343</td>\n",
       "      <td>58.396178</td>\n",
       "      <td>55025.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       open_houses    list_price   property_id  community    listing_id  \\\n",
       "count          0.0  7.721000e+03  8.159000e+03        0.0  7.752000e+03   \n",
       "mean           NaN  4.341582e+05  5.755508e+09        NaN  2.957819e+09   \n",
       "std            NaN  5.514925e+05  2.687366e+09        NaN  7.541620e+07   \n",
       "min            NaN  1.000000e+00  1.003443e+09        NaN  6.052327e+08   \n",
       "25%            NaN  2.090000e+05  3.307743e+09        NaN  2.959499e+09   \n",
       "50%            NaN  3.250000e+05  6.000993e+09        NaN  2.960836e+09   \n",
       "75%            NaN  4.999000e+05  8.169927e+09        NaN  2.961805e+09   \n",
       "max            NaN  1.250000e+07  9.993679e+09        NaN  2.963230e+09   \n",
       "\n",
       "       price_reduced_amount  source.plan_id  description.year_built  \\\n",
       "count          2.484000e+03    5.000000e+00             7316.000000   \n",
       "mean           2.442704e+04    4.170007e+11             1968.916074   \n",
       "std            7.162396e+04    0.000000e+00               35.096914   \n",
       "min            1.000000e+02    4.170007e+11             1828.000000   \n",
       "25%            6.000000e+03    4.170007e+11             1950.000000   \n",
       "50%            1.010000e+04    4.170007e+11             1975.000000   \n",
       "75%            2.000000e+04    4.170007e+11             1997.000000   \n",
       "max            2.015999e+06    4.170007e+11             2024.000000   \n",
       "\n",
       "       description.baths_3qtr  description.sold_price  ...  \\\n",
       "count              566.000000            6.716000e+03  ...   \n",
       "mean                 1.247350            4.126050e+05  ...   \n",
       "std                  0.463482            6.994308e+05  ...   \n",
       "min                  1.000000            3.080000e+02  ...   \n",
       "25%                  1.000000            1.910000e+05  ...   \n",
       "50%                  1.000000            3.140000e+05  ...   \n",
       "75%                  1.000000            4.700000e+05  ...   \n",
       "max                  3.000000            2.706500e+07  ...   \n",
       "\n",
       "       location.address.postal_code  location.address.coordinate.lon  \\\n",
       "count                   8159.000000                      7909.000000   \n",
       "mean                   50946.997181                       -92.206522   \n",
       "std                    29257.110670                        15.888886   \n",
       "min                     2111.000000                      -157.810583   \n",
       "25%                    25314.000000                      -104.971611   \n",
       "50%                    50310.000000                       -89.333131   \n",
       "75%                    78739.000000                       -78.617690   \n",
       "max                    99801.000000                       -71.006343   \n",
       "\n",
       "       location.address.coordinate.lat  location.county.fips_code  \\\n",
       "count                      7909.000000                7588.000000   \n",
       "mean                         39.009689               28000.253295   \n",
       "std                           4.374553               15586.751739   \n",
       "min                          21.277707                1101.000000   \n",
       "25%                          35.688084               16001.000000   \n",
       "50%                          39.698210               27123.000000   \n",
       "75%                          41.832266               41047.000000   \n",
       "max                          58.396178               55025.000000   \n",
       "\n",
       "       primary_photo  source  products  location.address.coordinate  \\\n",
       "count            0.0     0.0       0.0                          0.0   \n",
       "mean             NaN     NaN       NaN                          NaN   \n",
       "std              NaN     NaN       NaN                          NaN   \n",
       "min              NaN     NaN       NaN                          NaN   \n",
       "25%              NaN     NaN       NaN                          NaN   \n",
       "50%              NaN     NaN       NaN                          NaN   \n",
       "75%              NaN     NaN       NaN                          NaN   \n",
       "max              NaN     NaN       NaN                          NaN   \n",
       "\n",
       "       other_listings  location.county  \n",
       "count             0.0              0.0  \n",
       "mean              NaN              NaN  \n",
       "std               NaN              NaN  \n",
       "min               NaN              NaN  \n",
       "25%               NaN              NaN  \n",
       "50%               NaN              NaN  \n",
       "75%               NaN              NaN  \n",
       "max               NaN              NaN  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>8159</td>\n",
       "      <td>location.county</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8159</td>\n",
       "      <td>community</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8159</td>\n",
       "      <td>description.name</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8159</td>\n",
       "      <td>flags.is_new_construction</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8159</td>\n",
       "      <td>flags.is_for_rent</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                   col_name col_dtype  nunique unique  \\\n",
       "66         8159            location.county   float64        0  [nan]   \n",
       "10         8159                  community   float64        0  [nan]   \n",
       "25         8159           description.name   float64        0  [nan]   \n",
       "37         8159  flags.is_new_construction   float64        0  [nan]   \n",
       "38         8159          flags.is_for_rent   float64        0  [nan]   \n",
       "\n",
       "                   col_data_1                 col_data_2  \n",
       "66  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "10  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "25  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "37  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "38  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick look at the columns and the data in it -- Using a custom function, it sorts the df by the number of unique values in each column as well. \n",
    "columns_overview = cols_overview(data)\n",
    "\n",
    "columns_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with Nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 8159 Nulls : (17 Empty columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>8159</td>\n",
       "      <td>location.county</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8159</td>\n",
       "      <td>community</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8159</td>\n",
       "      <td>description.name</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>8159</td>\n",
       "      <td>flags.is_new_construction</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>8159</td>\n",
       "      <td>flags.is_for_rent</td>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                   col_name col_dtype  nunique unique  \\\n",
       "66         8159            location.county   float64        0  [nan]   \n",
       "10         8159                  community   float64        0  [nan]   \n",
       "25         8159           description.name   float64        0  [nan]   \n",
       "37         8159  flags.is_new_construction   float64        0  [nan]   \n",
       "38         8159          flags.is_for_rent   float64        0  [nan]   \n",
       "\n",
       "                   col_data_1                 col_data_2  \n",
       "66  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "10  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "25  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "37  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "38  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empties = columns_overview[columns_overview['nulls_count'] == data.shape[0]]\n",
    "\n",
    "empties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17,\n",
       " ['location.county',\n",
       "  'community',\n",
       "  'description.name',\n",
       "  'flags.is_new_construction',\n",
       "  'flags.is_for_rent',\n",
       "  'flags.is_subdivision',\n",
       "  'flags.is_contingent',\n",
       "  'flags.is_pending',\n",
       "  'flags.is_coming_soon',\n",
       "  'flags.is_plan',\n",
       "  'primary_photo',\n",
       "  'products',\n",
       "  'other_listings',\n",
       "  'open_houses',\n",
       "  'location.address.coordinate',\n",
       "  'description.baths_1qtr',\n",
       "  'source'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_empty = [i for i in empties['col_name']]\n",
    "\n",
    "len(is_empty), is_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the columns that are empty\n",
    "data.drop(columns=is_empty, inplace=True)\n",
    "\n",
    "data.shape[1] # From 67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop removed columns from columns_overview\n",
    "columns_overview.drop(index=empties.index, inplace=True)\n",
    "\n",
    "columns_overview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 7)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Base\n",
    "columns_overview.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>8154</td>\n",
       "      <td>community.description.name</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, Woods of Copper Creek]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8154</td>\n",
       "      <td>source.plan_id</td>\n",
       "      <td>float64</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, 417000743767.0]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8154</td>\n",
       "      <td>source.spec_id</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, 365-36546-365750000-0016]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>8154</td>\n",
       "      <td>community.advertisers</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, [{'office': {'hours': 'Monday - Saturday...</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8117</td>\n",
       "      <td>flags.is_foreclosure</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, True]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                    col_name col_dtype  nunique  \\\n",
       "49         8154  community.description.name    object        1   \n",
       "14         8154              source.plan_id   float64        1   \n",
       "16         8154              source.spec_id    object        1   \n",
       "48         8154       community.advertisers    object        1   \n",
       "34         8117        flags.is_foreclosure    object        1   \n",
       "\n",
       "                                               unique  \\\n",
       "49                       [nan, Woods of Copper Creek]   \n",
       "14                              [nan, 417000743767.0]   \n",
       "16                    [nan, 365-36546-365750000-0016]   \n",
       "48  [nan, [{'office': {'hours': 'Monday - Saturday...   \n",
       "34                                        [nan, True]   \n",
       "\n",
       "                   col_data_1                 col_data_2  \n",
       "49  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "14  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "16  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "48  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "34  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run the cols_overview function\n",
    "columns_overview = cols_overview(data)\n",
    "\n",
    "columns_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 8154 Nulls : `['community.description.name', 'source.plan_id', 'source.spec_id', 'community.advertisers']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['community.description.name',\n",
       " 'source.plan_id',\n",
       " 'source.spec_id',\n",
       " 'community.advertisers']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = columns_overview[columns_overview['nulls_count'] == 8154]['col_name'] # Get the columns with 8154 nulls\n",
    "\n",
    "remove_cols = [i for i in remove]\n",
    "remove_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=remove_cols, inplace=True)\n",
    "\n",
    "data.shape[1] # From 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8117</td>\n",
       "      <td>flags.is_foreclosure</td>\n",
       "      <td>object</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, True]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7593</td>\n",
       "      <td>description.baths_3qtr</td>\n",
       "      <td>float64</td>\n",
       "      <td>3</td>\n",
       "      <td>[nan, 2.0, 1.0, 3.0]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6808</td>\n",
       "      <td>virtual_tours</td>\n",
       "      <td>object</td>\n",
       "      <td>290</td>\n",
       "      <td>[nan, [{'type': None, 'href': 'https://youtube...</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6732</td>\n",
       "      <td>description.sub_type</td>\n",
       "      <td>object</td>\n",
       "      <td>2</td>\n",
       "      <td>[nan, condo, townhouse]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5878</td>\n",
       "      <td>description.baths_half</td>\n",
       "      <td>float64</td>\n",
       "      <td>5</td>\n",
       "      <td>[nan, 1.0, 2.0, 3.0, 4.0, 5.0]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                col_name col_dtype  nunique  \\\n",
       "32         8117    flags.is_foreclosure    object        1   \n",
       "17         7593  description.baths_3qtr   float64        3   \n",
       "9          6808           virtual_tours    object      290   \n",
       "25         6732    description.sub_type    object        2   \n",
       "21         5878  description.baths_half   float64        5   \n",
       "\n",
       "                                               unique  \\\n",
       "32                                        [nan, True]   \n",
       "17                               [nan, 2.0, 1.0, 3.0]   \n",
       "9   [nan, [{'type': None, 'href': 'https://youtube...   \n",
       "25                            [nan, condo, townhouse]   \n",
       "21                     [nan, 1.0, 2.0, 3.0, 4.0, 5.0]   \n",
       "\n",
       "                   col_data_1                 col_data_2  \n",
       "32  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "17  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "9   [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "25  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  \n",
       "21  [nan, nan, nan, nan, nan]  [nan, nan, nan, nan, nan]  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run the cols_overview function\n",
    "columns_overview = cols_overview(data)\n",
    "\n",
    "columns_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 8117 Nulls : `'flags.is_foreclosure'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kadm2\\AppData\\Local\\Temp\\ipykernel_10816\\318830356.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['flags.is_foreclosure'] = data['flags.is_foreclosure'].fillna(0).replace({True: 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The flags.is_foreclosure may be useful. It may have effect with the house price. Replacing the Nan values with 0 and 1.\n",
    "data['flags.is_foreclosure'] = data['flags.is_foreclosure'].fillna(0).replace({True: 1})\n",
    "\n",
    "data['flags.is_foreclosure'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 6808 Nulls : `'virtual_tours'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the NaN values with 0, and non-nulls with 1.\n",
    "data['virtual_tours'] = data['virtual_tours'].notnull().astype(int)\n",
    "\n",
    "data['virtual_tours'].unique() # We don't really need the values, just the presence of a virtual tour (True/False|0/1) which may have some effect on the price if the owner decided to pay more to have one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 7593 Nulls : `'description.baths_3qtr'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 3.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing the NaN values with 0\n",
    "data['description.baths_3qtr'] = data['description.baths_3qtr'].fillna(0.)\n",
    "\n",
    "data['description.baths_3qtr'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 6732 Nulls : `'description.sub_type'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No sub_type', 'condo', 'townhouse'], dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling a property a 'Condo' usually means they're charging more. Replacing Nan with 'No sub_type'\n",
    "data['description.sub_type'] = data['description.sub_type'].fillna('No sub_type')\n",
    "\n",
    "data['description.sub_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 5878 Nulls : `'description.baths_half'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It's possible to have 0 half baths. Replacing the NaN values with 0\n",
    "data['description.baths_half'] = data['description.baths_half'].fillna(0.)\n",
    "\n",
    "data['description.baths_half'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 5675 Nulls : `['flags.is_price_reduced', 'price_reduced_amount']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 2)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These columns appear to be related.\n",
    "compare = data[~data[['flags.is_price_reduced', 'price_reduced_amount']].isnull().all(axis=1)]\n",
    "\n",
    "compare[['flags.is_price_reduced', 'price_reduced_amount']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5675 + 2484 == 8159 # All the nulls are in the same rows. Replacing the NaN values with 0 on 'price_reduced_amount' and False on 'flags.is_price_reduced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kadm2\\AppData\\Local\\Temp\\ipykernel_10816\\4089715487.py:5: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data['flags.is_price_reduced'] = data['flags.is_price_reduced'].fillna(False)\n"
     ]
    }
   ],
   "source": [
    "# Replacing the NaN values with 0\n",
    "data['price_reduced_amount'] = data['price_reduced_amount'].fillna(0.)\n",
    "\n",
    "# Replacing the NaN values with False\n",
    "data['flags.is_price_reduced'] = data['flags.is_price_reduced'].fillna(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3711</td>\n",
       "      <td>description.garage</td>\n",
       "      <td>float64</td>\n",
       "      <td>9</td>\n",
       "      <td>[1.0, nan, 2.0, 3.0, 4.0, 6.0, 5.0, 9.0, 8.0, ...</td>\n",
       "      <td>[1.0, nan, nan, nan, nan]</td>\n",
       "      <td>[1.0, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1899</td>\n",
       "      <td>description.stories</td>\n",
       "      <td>float64</td>\n",
       "      <td>7</td>\n",
       "      <td>[nan, 1.0, 2.0, 3.0, 10.0, 6.0, 8.0, 4.0]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[2.0, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1443</td>\n",
       "      <td>description.sold_price</td>\n",
       "      <td>float64</td>\n",
       "      <td>738</td>\n",
       "      <td>[nan, 129900.0, 88500.0, 145000.0, 65000.0, 16...</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[99000.0, 29700.0, 162250.0, 63800.0, 115500.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1168</td>\n",
       "      <td>description.lot_sqft</td>\n",
       "      <td>float64</td>\n",
       "      <td>743</td>\n",
       "      <td>[10454.0, nan, 5875.0, 7476.0, 11761.0, 6534.0...</td>\n",
       "      <td>[10454.0, nan, nan, nan, nan]</td>\n",
       "      <td>[4792.0, 7841.0, 65340.0, nan, 52272.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>848</td>\n",
       "      <td>description.baths_full</td>\n",
       "      <td>float64</td>\n",
       "      <td>8</td>\n",
       "      <td>[2.0, nan, 1.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]</td>\n",
       "      <td>[2.0, nan, nan, nan, nan]</td>\n",
       "      <td>[1.0, 1.0, 1.0, nan, 2.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                col_name col_dtype  nunique  \\\n",
       "26         3711      description.garage   float64        9   \n",
       "27         1899     description.stories   float64        7   \n",
       "19         1443  description.sold_price   float64      738   \n",
       "22         1168    description.lot_sqft   float64      743   \n",
       "20          848  description.baths_full   float64        8   \n",
       "\n",
       "                                               unique  \\\n",
       "26  [1.0, nan, 2.0, 3.0, 4.0, 6.0, 5.0, 9.0, 8.0, ...   \n",
       "27          [nan, 1.0, 2.0, 3.0, 10.0, 6.0, 8.0, 4.0]   \n",
       "19  [nan, 129900.0, 88500.0, 145000.0, 65000.0, 16...   \n",
       "22  [10454.0, nan, 5875.0, 7476.0, 11761.0, 6534.0...   \n",
       "20      [2.0, nan, 1.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]   \n",
       "\n",
       "                       col_data_1  \\\n",
       "26      [1.0, nan, nan, nan, nan]   \n",
       "27      [nan, nan, nan, nan, nan]   \n",
       "19      [nan, nan, nan, nan, nan]   \n",
       "22  [10454.0, nan, nan, nan, nan]   \n",
       "20      [2.0, nan, nan, nan, nan]   \n",
       "\n",
       "                                         col_data_2  \n",
       "26                        [1.0, nan, nan, nan, nan]  \n",
       "27                        [2.0, nan, nan, nan, nan]  \n",
       "19  [99000.0, 29700.0, 162250.0, 63800.0, 115500.0]  \n",
       "22          [4792.0, 7841.0, 65340.0, nan, 52272.0]  \n",
       "20                        [1.0, 1.0, 1.0, nan, 2.0]  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run the cols_overview function\n",
    "columns_overview = cols_overview(data)\n",
    "\n",
    "columns_overview.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 3711 Nulls : `'description.garage'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can assume Nan means no garage. Replacing the NaN values with 0\n",
    "data['description.garage'] = data['description.garage'].fillna(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 1899 Nulls : `'description.stories'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1899 nulls\n",
    "# 1.0 can be a good guess for the NaN values... unsure..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 1443 Nulls : `'description.sold_price'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1443 nulls\n",
    "# Can't guess/assume anything yet... will leave it as is for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 1168 Nulls : `'description.lot_sqft'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1168 nulls\n",
    "# We can't just replace with 0, may need further investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 848 Nulls : `'description.baths_full'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the NaN values with 0\n",
    "data['description.baths_full'] = data['description.baths_full'].fillna(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nulls_count</th>\n",
       "      <th>col_name</th>\n",
       "      <th>col_dtype</th>\n",
       "      <th>nunique</th>\n",
       "      <th>unique</th>\n",
       "      <th>col_data_1</th>\n",
       "      <th>col_data_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1899</td>\n",
       "      <td>description.stories</td>\n",
       "      <td>float64</td>\n",
       "      <td>7</td>\n",
       "      <td>[nan, 1.0, 2.0, 3.0, 10.0, 6.0, 8.0, 4.0]</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[2.0, nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1443</td>\n",
       "      <td>description.sold_price</td>\n",
       "      <td>float64</td>\n",
       "      <td>738</td>\n",
       "      <td>[nan, 129900.0, 88500.0, 145000.0, 65000.0, 16...</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[99000.0, 29700.0, 162250.0, 63800.0, 115500.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1168</td>\n",
       "      <td>description.lot_sqft</td>\n",
       "      <td>float64</td>\n",
       "      <td>743</td>\n",
       "      <td>[10454.0, nan, 5875.0, 7476.0, 11761.0, 6534.0...</td>\n",
       "      <td>[10454.0, nan, nan, nan, nan]</td>\n",
       "      <td>[4792.0, 7841.0, 65340.0, nan, 52272.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>843</td>\n",
       "      <td>description.year_built</td>\n",
       "      <td>float64</td>\n",
       "      <td>147</td>\n",
       "      <td>[1963.0, nan, 1969.0, 1920.0, 2002.0, 1998.0, ...</td>\n",
       "      <td>[1963.0, nan, nan, nan, nan]</td>\n",
       "      <td>[1910.0, nan, nan, nan, 1950.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>836</td>\n",
       "      <td>description.sqft</td>\n",
       "      <td>float64</td>\n",
       "      <td>1119</td>\n",
       "      <td>[1821.0, nan, 950.0, 3860.0, 1375.0, 1478.0, 1...</td>\n",
       "      <td>[1821.0, nan, nan, nan, nan]</td>\n",
       "      <td>[1214.0, 988.0, 1470.0, nan, 3858.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>756</td>\n",
       "      <td>primary_photo.href</td>\n",
       "      <td>object</td>\n",
       "      <td>1627</td>\n",
       "      <td>[https://ap.rdcpix.com/07097d34c98a59ebb799688...</td>\n",
       "      <td>[https://ap.rdcpix.com/07097d34c98a59ebb799688...</td>\n",
       "      <td>[https://ap.rdcpix.com/b02cba9b2211b1157e67775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>756</td>\n",
       "      <td>photos</td>\n",
       "      <td>object</td>\n",
       "      <td>1627</td>\n",
       "      <td>[[{'tags': [{'label': 'house_view', 'probabili...</td>\n",
       "      <td>[[{'tags': [{'label': 'house_view', 'probabili...</td>\n",
       "      <td>[[{'tags': [{'label': 'house_view', 'probabili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>655</td>\n",
       "      <td>description.beds</td>\n",
       "      <td>float64</td>\n",
       "      <td>13</td>\n",
       "      <td>[3.0, nan, 2.0, 5.0, 4.0, 1.0, 6.0, 12.0, 7.0,...</td>\n",
       "      <td>[3.0, nan, nan, nan, nan]</td>\n",
       "      <td>[3.0, 3.0, 3.0, 0.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>571</td>\n",
       "      <td>location.county.fips_code</td>\n",
       "      <td>float64</td>\n",
       "      <td>65</td>\n",
       "      <td>[nan, 1101.0, 5119.0, 5125.0, 4013.0, 6067.0, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan]</td>\n",
       "      <td>[54039.0, 54039.0, 54039.0, 54039.0, 54039.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>521</td>\n",
       "      <td>tags</td>\n",
       "      <td>object</td>\n",
       "      <td>1628</td>\n",
       "      <td>[['carport', 'community_outdoor_space', 'cul_d...</td>\n",
       "      <td>[['carport', 'community_outdoor_space', 'cul_d...</td>\n",
       "      <td>[['central_air', 'forced_air', 'basement', 'tw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nulls_count                   col_name col_dtype  nunique  \\\n",
       "27         1899        description.stories   float64        7   \n",
       "19         1443     description.sold_price   float64      738   \n",
       "22         1168       description.lot_sqft   float64      743   \n",
       "16          843     description.year_built   float64      147   \n",
       "23          836           description.sqft   float64     1119   \n",
       "13          756         primary_photo.href    object     1627   \n",
       "8           756                     photos    object     1627   \n",
       "28          655           description.beds   float64       13   \n",
       "44          571  location.county.fips_code   float64       65   \n",
       "1           521                       tags    object     1628   \n",
       "\n",
       "                                               unique  \\\n",
       "27          [nan, 1.0, 2.0, 3.0, 10.0, 6.0, 8.0, 4.0]   \n",
       "19  [nan, 129900.0, 88500.0, 145000.0, 65000.0, 16...   \n",
       "22  [10454.0, nan, 5875.0, 7476.0, 11761.0, 6534.0...   \n",
       "16  [1963.0, nan, 1969.0, 1920.0, 2002.0, 1998.0, ...   \n",
       "23  [1821.0, nan, 950.0, 3860.0, 1375.0, 1478.0, 1...   \n",
       "13  [https://ap.rdcpix.com/07097d34c98a59ebb799688...   \n",
       "8   [[{'tags': [{'label': 'house_view', 'probabili...   \n",
       "28  [3.0, nan, 2.0, 5.0, 4.0, 1.0, 6.0, 12.0, 7.0,...   \n",
       "44  [nan, 1101.0, 5119.0, 5125.0, 4013.0, 6067.0, ...   \n",
       "1   [['carport', 'community_outdoor_space', 'cul_d...   \n",
       "\n",
       "                                           col_data_1  \\\n",
       "27                          [nan, nan, nan, nan, nan]   \n",
       "19                          [nan, nan, nan, nan, nan]   \n",
       "22                      [10454.0, nan, nan, nan, nan]   \n",
       "16                       [1963.0, nan, nan, nan, nan]   \n",
       "23                       [1821.0, nan, nan, nan, nan]   \n",
       "13  [https://ap.rdcpix.com/07097d34c98a59ebb799688...   \n",
       "8   [[{'tags': [{'label': 'house_view', 'probabili...   \n",
       "28                          [3.0, nan, nan, nan, nan]   \n",
       "44                          [nan, nan, nan, nan, nan]   \n",
       "1   [['carport', 'community_outdoor_space', 'cul_d...   \n",
       "\n",
       "                                           col_data_2  \n",
       "27                          [2.0, nan, nan, nan, nan]  \n",
       "19    [99000.0, 29700.0, 162250.0, 63800.0, 115500.0]  \n",
       "22            [4792.0, 7841.0, 65340.0, nan, 52272.0]  \n",
       "16                    [1910.0, nan, nan, nan, 1950.0]  \n",
       "23               [1214.0, 988.0, 1470.0, nan, 3858.0]  \n",
       "13  [https://ap.rdcpix.com/b02cba9b2211b1157e67775...  \n",
       "8   [[{'tags': [{'label': 'house_view', 'probabili...  \n",
       "28                          [3.0, 3.0, 3.0, 0.0, 3.0]  \n",
       "44      [54039.0, 54039.0, 54039.0, 54039.0, 54039.0]  \n",
       "1   [['central_air', 'forced_air', 'basement', 'tw...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Re-run the cols_overview function\n",
    "columns_overview = cols_overview(data)\n",
    "\n",
    "columns_overview.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 843 Nulls : `'description.year_built'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 836 Nulls : `'description.sqft'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 756 Nulls : `['primary_photo.href', 'photos']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7403, 2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 756 nulls\n",
    "# These columns appear to be related.\n",
    "compare = data[~data[['primary_photo.href', 'photos']].isnull().all(axis=1)]\n",
    "\n",
    "compare[['primary_photo.href', 'photos']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "756 + 7403 == 8159 # All the nulls are in the same rows. Creating a new column 'has_photos' which will be 0 or 1, and then dropping both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['has_photos'] = data['photos'].notnull().astype(int)\n",
    "\n",
    "data['has_photos'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['primary_photo.href', 'photos'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 655 Nulls : `'description.beds'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 571 Nulls : `'location.county.fips_code'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 521 Nulls : `'tags'` -- *Gets its own section further down*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 486 Nulls : `'products.brand_name'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation\n",
    "# May be connected to source.agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 438 Nulls : `'list_price'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 407 Nulls : `['source.agents', 'listing_id', 'flags.is_new_listing', 'list_date', 'source.type']` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'source.agents' may be connected to 'products.brand_name' and/or 'source.type'\n",
    "# 'flags.is_new_listing' may be connected to 'list_date'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 303 Nulls : `'other_listings.rdc'`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will probably drop this column. It's not clear what it is.\n",
    "data.drop(columns='other_listings.rdc', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 250 Nulls : `['location.address.coordinate.lon', 'location.address.coordinate.lat']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be inferred from the rest of the location data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 179 Nulls : `'description.baths'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs further investigation\n",
    "# Look into all the columns that have 'baths' in the name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 34 Nulls : `'last_update_date', 'description.type'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May drop these nulls, but will check if they're connected to other columns first.\n",
    "# 'last_update_date' may be connected to 'list_date'\n",
    "# 'description.type' may be connected to 'description.sub_type'... 'description.type' has the sub_type values. Can probably just merge these 2 columns to avoid redundancy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 15 Nulls : `'location.address.line'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can probably infer 'location.address.coordinate.lon' and 'location.address.coordinate.lat' (250 locations with null) from 'location.address.line' (Only 15 nulls.)\n",
    "# Need map data. Google Maps API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 10 Nulls : `'location.county.name'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can probably infer from the rest of the location data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - 5 Nulls : `'location.address.city'` -- *Look again*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can probably infer from the rest of the location data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the fact that with tags, there are a lot of categorical variables.\n",
    "- How many columns would we have if we OHE tags, city and state?\n",
    "- Perhaps we can get rid of tags that have a low frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OHE categorical variables/ tags here\n",
    "# tags will have to be done manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sales will vary drastically between cities and states.  Is there a way to keep information about which city it is without OHE?\n",
    "- Could we label encode or ordinal encode?  Yes, but this may have undesirable effects, giving nominal data ordinal values.\n",
    "- What we can do is use our training data to encode the mean sale price by city as a feature (a.k.a. Target Encoding)\n",
    "    - We can do this as long as we ONLY use the training data - we're using the available data to give us a 'starting guess' of the price for each city, without needing to encode city explicitly\n",
    "- If you replace cities or states with numerical values (like the mean price), make sure that the data is split so that we don't leak data into the training selection. This is a great time to train test split. Compute on the training data, and join these values to the test data\n",
    "- Note that you *may* have cities in the test set that are not in the training set. You don't want these to be NA, so maybe you can fill them with the overall mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train test split here\n",
    "# do something with state and city"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Data - STRETCH\n",
    "\n",
    "> This doesn't need to be part of your Minimum Viable Product (MVP). We recommend you write a functional, basic pipeline first, then circle back and join new data if you have time\n",
    "\n",
    "> If you do this, try to write your downstream steps in a way it will still work on a dataframe with different features!\n",
    "\n",
    "- You're not limited to just using the data provided to you. Think/ do some research about other features that might be useful to predict housing prices. \n",
    "- Can you import and join this data? Make sure you do any necessary preprocessing and make sure it is joined correctly.\n",
    "- Example suggestion: could mortgage interest rates in the year of the listing affect the price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import, join and preprocess new data here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA/ Visualization\n",
    "\n",
    "Remember all of the EDA that you've been learning about?  Now is a perfect time for it!\n",
    "- Look at distributions of numerical variables to see the shape of the data and detect outliers.    \n",
    "    - Consider transforming very skewed variables\n",
    "- Scatterplots of a numerical variable and the target go a long way to show correlations.\n",
    "- A heatmap will help detect highly correlated features, and we don't want these.\n",
    "    - You may have too many features to do this, in which case you can simply compute the most correlated feature-pairs and list them\n",
    "- Is there any overlap in any of the features? (redundant information, like number of this or that room...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform EDA here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling and Finishing Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now is a great time to scale the data and save it once it's preprocessed.\n",
    "- You can save it in your data folder, but you may want to make a new `processed/` subfolder to keep it organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_path = '../processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ang-lhl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
